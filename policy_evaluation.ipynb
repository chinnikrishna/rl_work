{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84080b26",
   "metadata": {},
   "source": [
    "# Policy Evaluation\n",
    "\n",
    "A Policy is a mapping from state to action. \n",
    "\n",
    "Let us assume an environment with 7 states. \n",
    "State 0 and State 6 are terminating states. State 0 is a hole and yields a reward of 0. State 6 is a Goal with a reward of 1. \n",
    "\n",
    "Agent starts in state  3 and perform actions left (0) and right (1). \n",
    "\n",
    "Transition Probabilities are as follows\n",
    "\n",
    "50% of the time action succeeds. 33.33% of the time agent doesnt move on an action. 16.66% of the time agent move in the opposite direction of action.\n",
    "\n",
    "|H&nbsp;0|&nbsp;&nbsp;1&nbsp;&nbsp;|&nbsp;&nbsp;2&nbsp;&nbsp;|&nbsp;&nbsp;S&nbsp;3&nbsp;|&nbsp;&nbsp;4&nbsp;&nbsp;|&nbsp;&nbsp;5&nbsp;&nbsp;|&nbsp;&nbsp;G&nbsp;6&nbsp;|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c1972e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': '{: 0.4f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "794cc17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment modeled as dict of dictionaries\n",
    "# Tuples are encoded as [Probability, next state, reward, terminal state]\n",
    "class BSW:\n",
    "    def __init__(self):\n",
    "        self.state = None\n",
    "        self.render_once = False\n",
    "        \n",
    "    def reset(self, start_state=3):\n",
    "        self.bw_env = {\n",
    "            0: {\n",
    "                0: [1.0, 0, 0.0, True],\n",
    "                1: [1.0, 0, 0.0, True],\n",
    "            },\n",
    "            1: {\n",
    "                0: [1.0, 0, 0.0, False],\n",
    "                1: [1.0, 2, 0.0, False],\n",
    "            },\n",
    "            2: {\n",
    "                0: [1.0, 1, 0.0, False],\n",
    "                1: [1.0, 3, 0.0, False],\n",
    "            },\n",
    "            3: {\n",
    "                0: [1.0, 2, 0.0, False],\n",
    "                1: [1.0, 4, 0.0, False],\n",
    "            },\n",
    "            4: {\n",
    "                0: [1.0, 3, 0.0, False],\n",
    "                1: [1.0, 5, 0.0, False],\n",
    "            },\n",
    "            5: {\n",
    "                0: [1.0, 4, 0.0, False],\n",
    "                1: [1.0, 6, 1.0, True],\n",
    "            },\n",
    "            6: {\n",
    "                0: [1.0, 6, 0.0, True],\n",
    "                1: [1.0, 6, 0.0, True],\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        self.bsw_env = {\n",
    "            0: {\n",
    "                0:[(1.0, 0, 0.0, True)],\n",
    "                1:[(1.0, 0, 0.0, True)]\n",
    "            },\n",
    "            1: {\n",
    "                0:[(0.50, 0, 0.0, False),\n",
    "                   (0.34, 1, 0.0, False),\n",
    "                   (0.16, 2, 0.0, False)],\n",
    "                1:[(0.50, 2, 0.0, False),\n",
    "                   (0.34, 1, 0.0, False),\n",
    "                   (0.16, 0, 0.0, False)],\n",
    "             },\n",
    "            2: {\n",
    "                0:[(0.50, 1, 0.0, False),\n",
    "                   (0.34, 2, 0.0, False),\n",
    "                   (0.16, 3, 0.0, False)],\n",
    "                1:[(0.50, 3, 0.0, False),\n",
    "                   (0.34, 2, 0.0, False),\n",
    "                   (0.16, 1, 0.0, False)],\n",
    "             },\n",
    "            3: {\n",
    "                0:[(0.50, 2, 0.0, False),\n",
    "                   (0.34, 3, 0.0, False),\n",
    "                   (0.16, 4, 0.0, False)],\n",
    "                1:[(0.50, 4, 0.0, False),\n",
    "                   (0.34, 3, 0.0, False),\n",
    "                   (0.16, 2, 0.0, False)],\n",
    "             },\n",
    "            4: {\n",
    "                0:[(0.50, 3, 0.0, False),\n",
    "                   (0.34, 4, 0.0, False),\n",
    "                   (0.16, 5, 0.0, False)],\n",
    "                1:[(0.50, 5, 0.0, False),\n",
    "                   (0.34, 4, 0.0, False),\n",
    "                   (0.16, 3, 0.0, False)],\n",
    "             },\n",
    "            5: {\n",
    "                0:[(0.50, 4, 0.0, False),\n",
    "                   (0.34, 5, 0.0, False),\n",
    "                   (0.16, 6, 1.0, True)],\n",
    "                1:[(0.50, 6, 1.0, True),\n",
    "                   (0.34, 5, 0.0, False),\n",
    "                   (0.16, 4, 0.0, False)],\n",
    "             },\n",
    "            6: {\n",
    "                0:[(1.0, 6, 0.0, True)],\n",
    "                1:[(1.0, 6, 0.0, True)]\n",
    "            }\n",
    "        }\n",
    "        self.state = start_state\n",
    "        reward = [1.0 if self.state == 6 else 0.0]\n",
    "        done = [True if (self.state == 6 or self.state==0) else False]\n",
    "        return self.state, reward[0], done[0]\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Get tuple of next possible states\n",
    "        transition_tuples = self.bsw_env[self.state][action]\n",
    "        # Separate tuple into prob, next states, rewards and done\n",
    "        trans_probs = [i[0] for i in transition_tuples]\n",
    "        nps = [i[1] for i in transition_tuples]\n",
    "        rewards = [i[2] for i in transition_tuples]\n",
    "        done_vals = [i[3] for i in transition_tuples]\n",
    "        # Select next state index based on trans_probs\n",
    "        ns_idx = np.random.choice([i for i in range(len(transition_tuples))], p=trans_probs)\n",
    "        # Set state of environment\n",
    "        self.state = nps[ns_idx]\n",
    "        return (self.state, rewards[ns_idx], done_vals[ns_idx])\n",
    "    \n",
    "    def render(self, print_state_names=False):\n",
    "        if print_state_names:\n",
    "            print(\"|  H-0  |  1  |  2  |  3  |  4  |  5  |  G-6  |\")\n",
    "        for i in range(7):\n",
    "            str_to_print = \"|  \"\n",
    "            if i == 0:\n",
    "                str_to_print += \"  \"\n",
    "            if i == self.state:\n",
    "                str_to_print += \"A\"\n",
    "                str_to_print += \"  \"\n",
    "            else:\n",
    "                str_to_print += \"   \"\n",
    "            if i == 6:\n",
    "                str_to_print += \"  |\"\n",
    "            print(str_to_print, end='')\n",
    "        print(\"\")\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b854984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0000  0.0023  0.0094  0.0317  0.1014  0.3193  0.0000]\n"
     ]
    }
   ],
   "source": [
    "env = BSW()\n",
    "state, reward, done = env.reset(start_state=3)\n",
    "# Policy Evaluation\n",
    "num_episodes = 20\n",
    "action = 0\n",
    "\n",
    "def svf(env, action, theta=1e-10):\n",
    "    P = env.bsw_env\n",
    "    prev_vfunc = np.zeros(len(P))\n",
    "    while True:\n",
    "        vfunc = np.zeros(len(P))\n",
    "        for s in range(len(P)):\n",
    "            for prob, ns, reward, done in P[s][action]:\n",
    "                vfunc[s] += prob * (reward + (1.0 * prev_vfunc[ns] * (not done)))\n",
    "        if np.max(np.abs(prev_vfunc - vfunc)) < theta:\n",
    "            break\n",
    "        prev_vfunc = vfunc.copy()  \n",
    "    return vfunc\n",
    "\n",
    "v = svf(env, action)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "907f73c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000  0.0023  0.0094  0.0317  0.1014  0.3193  0.0000]\n",
      " [ 0.0000  0.6807  0.8986  0.9683  0.9906  0.9977  0.0000]]\n"
     ]
    }
   ],
   "source": [
    "def avf(env, theta=1e-10):\n",
    "    actions = [0, 1]\n",
    "    P = env.bsw_env\n",
    "    prev_avfunc = np.zeros(shape=(len(actions), len(P)))\n",
    "    while True:\n",
    "        avfunc = np.zeros(shape=(len(actions), len(P)))\n",
    "        for action in actions:\n",
    "            for state in range(len(P)):\n",
    "                for prob, ns, reward, done in P[state][action]:\n",
    "                    avfunc[action][state] += prob * (reward + 1.0 * prev_avfunc[action][ns] * (not done))\n",
    "        if np.max(np.abs(prev_avfunc - avfunc)) < theta:\n",
    "            break\n",
    "        prev_avfunc = avfunc.copy()\n",
    "    return avfunc\n",
    "avfunc = avf(env)\n",
    "print(avfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dde62b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000]\n",
      "[ 0.0000  0.6784  0.8891  0.9365  0.8891  0.6784  0.0000]\n"
     ]
    }
   ],
   "source": [
    "print(avfunc[0] - v)\n",
    "print(avfunc[1] - v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
